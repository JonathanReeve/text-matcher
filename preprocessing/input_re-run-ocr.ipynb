{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Import libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "from text_matcher.matcher import Text, Matcher\n",
            "import json\n",
            "import pandas as pd\n",
            "import random\n",
            "from IPython.display import clear_output\n",
            "%matplotlib inline\n",
            "import matplotlib.pyplot as plt\n",
            "plt.rcParams[\"figure.figsize\"] = [16, 6]\n",
            "#pd.set_option('display.max_colwidth', None)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Load in our Data Files\n",
            "\n",
            "üõë Input a link to the json file of articles to run the spell-check on\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Load in the JSON file with our JSTOR articles and data from TextMatcher\n",
            "# (Note: must have the file 'default.json' in the same directory as this notebook)\n",
            "articles = pd.read_json('../algorithm-testing/jstor-gender-trouble-all-articles.jsonl', lines=True)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Importing the spell-check package\n",
            "\n",
            "Languages tested:\n",
            "* English - ‚Äòen‚Äô\n",
            "* Spanish - ‚Äòes‚Äô\n",
            "* French - ‚Äòfr‚Äô\n",
            "* German - ‚Äòde‚Äô\n",
            "\n",
            "Make sure to run `pip install pyspellchecker` in terminal before running the cell below\n",
            "\n",
            "Recommended upper bound of anomaly beyond 75% percentile based on normal distribution:\n",
            "\n",
            "    mean = 0.12764241550612537\n",
            "    n = 30\n",
            "    std = 0.02330421008\n",
            "    [25 percentile, 75 percentile]: [0.1119237258,0.1433611052]\n",
            "\n",
            "    Reccomended bound: 85.66\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "{}\n"
               ]
            }
         ],
         "source": [
            "from spellchecker import SpellChecker\n",
            "\n",
            "# ‚ÄºÔ∏è üõë Make sure to change the variable below to the desired accuracy bound üõë  ‚ÄºÔ∏è\n",
            "bound = 85.66\n",
            "\n",
            "#initialize dictionary pairing readability scores and article id's\n",
            "articles_read_scores = {}\n",
            "\n",
            "#print(len(articles.index))\n",
            "\n",
            "# goes through each row (article) in the dataframe:\n",
            "for index in range(0,1):\n",
            "    article_index = index\n",
            "\n",
            "    # defining variables\n",
            "    article_id  = articles['id'].loc[article_index] \n",
            "    article_text = articles['fullText'].loc[article_index]\n",
            "    article_title = articles['title'].loc[article_index]\n",
            "\n",
            "    # Assign the full text of this article to a variable called `cleaned_article_text`, with text-matcher's Text function\n",
            "    cleaned_article_text = Text(article_text, article_title)\n",
            "\n",
            "    word_list = cleaned_article_text.getTokens()\n",
            "    \n",
            "    #word_list = ((\" \").join(cleaned_article_text)).split(\" \")\n",
            "\n",
            "    #word_list = random.sample(word_list, int(len(word_list)/float(1)))\n",
            "\n",
            "    #word_list = word_list[:int(len(word_list)*6/10)]\n",
            "\n",
            "    # finding the document language\n",
            "    languages = ['en','fr','es','de']\n",
            "    abbrev_word_list = word_list[:50]\n",
            "    incorrect = []\n",
            "    for lg in languages:\n",
            "        spell = SpellChecker(language = lg)\n",
            "        misspelled = spell.unknown(abbrev_word_list)\n",
            "        incorrect.append(len(misspelled))\n",
            "    lang = languages[incorrect.index(min(incorrect))]\n",
            "\n",
            "    # find those words that may be misspelled\n",
            "    spell = SpellChecker(language = lang)\n",
            "    misspelled = spell.unknown(word_list)\n",
            "\n",
            "incorrect_percentage = float(min(incorrect))/len(word_list)\n",
            "\n"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Run OCR On PDF\n",
            "\n",
            "This cell converts a pdf to an image and then runs ocr on it.\n",
            "   \n",
            "Before this can work, you need to install tesseract and all tesseract languages. This can be done with \"brew install tesseract\" and \"brew install tesseract-lang\" on Mac. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "from PIL import Image\n",
            "import pytesseract\n",
            "import urllib.request\n",
            "from pdf2image import convert_from_path\n",
            "\n",
            "pdf = \"test_english.pdf\"\n",
            "pages = convert_from_path(pdf)\n",
            "\n",
            "new_ocr_text = \"\"\n",
            "for page in pages[1:]:\n",
            "    new_ocr_text += pytesseract.image_to_string(page, lang=\"eng\")"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Rerun Spellcheck"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 28,
         "metadata": {},
         "outputs": [],
         "source": [
            "spell_check_language = 'en'\n",
            "spell = SpellChecker(language = spell_check_language)\n",
            "text = Text(new_ocr_text, \"Title\")\n",
            "word_list = text.getTokens()\n",
            "misspelled = spell.unknown(word_list)\n",
            "incorrect_percentage = float(len(misspelled))/len(word_list)\n",
            "print(\"New incorrect percentage\": incorrect_percentage)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
