{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Import libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "from text_matcher.matcher import Text, Matcher\n",
            "import json\n",
            "import pandas as pd\n",
            "import random\n",
            "from IPython.display import clear_output\n",
            "%matplotlib inline\n",
            "import matplotlib.pyplot as plt\n",
            "plt.rcParams[\"figure.figsize\"] = [16, 6]\n",
            "#pd.set_option('display.max_colwidth', None)\n",
            "import os, json, uuid"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Load in our Data Files\n",
            "\n",
            "üõë Input a link to the json file of articles to run the spell-check on\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Load in the JSON file with our JSTOR articles and data from TextMatcher\n",
            "# (Note: must have the file 'default.json' in the same directory as this notebook)\n",
            "articles = pd.read_json('../algorithm-testing/jstor-gender-trouble-all-articles.jsonl', lines=True)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Importing the spell-check package\n",
            "\n",
            "Languages tested:\n",
            "* English - ‚Äòen‚Äô\n",
            "* Spanish - ‚Äòes‚Äô\n",
            "* French - ‚Äòfr‚Äô\n",
            "* German - ‚Äòde‚Äô\n",
            "\n",
            "Make sure to run `pip install pyspellchecker` in terminal before running the cell below\n",
            "\n",
            "Recommended upper bound of anomaly beyond 75% percentile based on normal distribution:\n",
            "\n",
            "    mean = 0.12764241550612537\n",
            "    n = 30\n",
            "    std = 0.02330421008\n",
            "    [25 percentile, 75 percentile]: [0.1119237258,0.1433611052]\n",
            "\n",
            "    Reccomended bound: 85.66\n",
            "\n",
            "20 articles in 12.7 seconds: 0.64\n",
            "\n",
            "50 articles in 39.7 seconds: 0.79\n",
            "\n",
            "100 articles in 59.4 seconds: 0.594\n",
            "\n",
            "500 articles in 385.5 seconds: 0.77\n",
            "\n",
            "~ 0.775 seconds/article from median of 100 articles"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "from spellchecker import SpellChecker\n",
            "\n",
            "# ‚ÄºÔ∏è üõë Make sure to change the variable below to the desired accuracy bound üõë  ‚ÄºÔ∏è\n",
            "bound = 85.66\n",
            "\n",
            "#initialize dictionary pairing readability scores and article id's\n",
            "articles_read_scores = {}\n",
            "\n",
            "# goes through each row (article) in the dataframe:\n",
            "\n",
            "for index in range(len(articles)):\n",
            "    article_index = index\n",
            "    \n",
            "    # defining variables\n",
            "    article_id  = articles['id'].loc[article_index] \n",
            "    article_text = articles['fullText'].loc[article_index]\n",
            "    article_title = articles['title'].loc[article_index]\n",
            "\n",
            "    # get articleID number\n",
            "    article_number = article_id.split('/')[-1]\n",
            "\n",
            "    # Assign the full text of this article to a variable called `cleaned_article_text`, with text-matcher's Text function\n",
            "    cleaned_article_text = Text(article_text, article_title)\n",
            "\n",
            "    word_list = cleaned_article_text.getTokens()\n",
            "    \n",
            "    # finding the document language\n",
            "    languages = ['en','fr','es','de']\n",
            "    abbrev_word_list = random.sample(word_list, int(len(word_list)/float(40)))\n",
            "    incorrect = []\n",
            "    for lg in languages:\n",
            "        spell = SpellChecker(language = lg)\n",
            "        misspelled = spell.unknown(abbrev_word_list)\n",
            "        incorrect.append(len(misspelled))\n",
            "    lang = languages[incorrect.index(min(incorrect))]\n",
            "\n",
            "    # find those words that may be misspelled\n",
            "    spell = SpellChecker(language = lang)\n",
            "    misspelled = spell.unknown(word_list)\n",
            "\n",
            "    # output the readability score \n",
            "    incorrect_percentage = float(len(misspelled))/len(word_list)\n",
            "\n",
            "    #adds the article id:[index, title, and percentage] to the dictionary\n",
            "    if (1 - incorrect_percentage) < float(bound)/100 and lang == 'en':\n",
            "        articles_read_scores[article_number] = [article_id, article_index, article_title, incorrect_percentage, lang]\n",
            "\n",
            "#articles and scores stored in dictionary articles_read_scores\n",
            "articles_scores = pd.DataFrame.from_dict(articles_read_scores, orient='index', columns=['ArticleID', 'OriginalIndex', 'Title', 'Score', 'Language'])"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Visualizing the article scores as a table"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "display(articles_scores)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Run OCR On PDF\n",
            "\n",
            "## Preparing for rerunning OCR\n",
            "\n",
            "Download the pdf's of the articles listed above and place them into a folder called 'incorrect_articles_pdfs'\n",
            "\n",
            "Name the pdfs with the corresponding articleID number (ie 409787) (JSTOR should automatically do this when you download the files)."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Rerunning OCR and Spellcheck\n",
            "\n",
            "This cell iterates through all the pdfs in the \"incorrect_articles_pdfs\" folder, reruns ocr on them, runs spellcheck on the new ocr-ed text, and replaces the article text in the json data file. \n",
            "   \n",
            "Before this can work, you need to install tesseract and all tesseract languages. This can be done with \"brew install tesseract\" and \"brew install tesseract-lang\" on Mac. For other installation, check the documenation: https://tesseract-ocr.github.io/\n",
            "\n",
            "You also need to install pdf2image, which converts the pdf into an image usuable for the tesseract OCR. Installation guide here: https://pypi.org/project/pdf2image/"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ‚ÄºÔ∏è üõë Make sure to change the variable below to the desired replacement bound (ie how much improvement to replace the old OCR with new OCR) üõë  ‚ÄºÔ∏è\n",
            "\n",
            "replace = 0.10\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import pytesseract\n",
            "from pdf2image import convert_from_path\n",
            "import os\n",
            "\n",
            "# mapping of language shortcut for spellcheck to tessarect\n",
            "lang_mapping = {\n",
            "    \"en\": \"eng\",\n",
            "    \"es\": \"spa\",\n",
            "    \"fr\": \"fra\",\n",
            "    \"de\": \"deu\"\n",
            "}\n",
            "\n",
            "folder = \"./incorrect_articles_pdfs\"\n",
            "\n",
            "articles_chg = pd.read_json('../algorithm-testing/jstor-gender-trouble-all-articles.jsonl', lines=True)\n",
            "\n",
            "no_improvement = {}\n",
            "\n",
            "for pdf in os.listdir(folder):\n",
            "\n",
            "    # remove the \".pdf\" to have the article_number\n",
            "    article_number = pdf[:-4]\n",
            "\n",
            "    # converts the pdf into images that are used for OCR \n",
            "    pdf_page_images = convert_from_path(\"incorrect_articles_pdfs/\" + pdf)  \n",
            "\n",
            "    pdf_lang = articles_read_scores[article_number][4]\n",
            "    article_title = articles_read_scores[article_number][2]\n",
            "\n",
            "    # run ocr \n",
            "    new_ocr_text = []\n",
            "    for image in pdf_page_images[1:]:\n",
            "        new_ocr_text.append(pytesseract.image_to_string(image, lang=lang_mapping[pdf_lang]))\n",
            "\n",
            "    # rerun spellcheck for readability score\n",
            "    spell = SpellChecker(language = pdf_lang)\n",
            "    text = Text(new_ocr_text, article_title)\n",
            "    word_list = text.getTokens()\n",
            "    misspelled = spell.unknown(word_list)\n",
            "    incorrect_percentage = float(len(misspelled))/len(word_list)\n",
            "    print(f\"New incorrect percentage for:{article_number}\", incorrect_percentage)\n",
            "\n",
            "    # update the article text in the new dataframe based on the error change \n",
            "    old_error = float(articles_scores.loc[article_number, ['Score']])\n",
            "    index = int(articles_scores.at[article_number, \"OriginalIndex\"]) # gets the index in the original jsonl file\n",
            "    if old_error - incorrect_percentage > replace:\n",
            "        articles_chg.at[index, \"fullText\"] = new_ocr_text\n",
            "        print('+')\n",
            "    else:\n",
            "        no_improvement[article_number] = [article_number, article_title, articles_scores.loc[article_number, ['ArticleID']], old_error, pdf_lang]\n",
            "        print('-')\n",
            "\n",
            "# save the new dataframe as a new jsonl file (input what you want the name of the file to be here)\n",
            "articles_chg.to_json(\"../algorithm-testing/jstor-gender-trouble-all-articles-updated.jsonl\", orient='records', lines=True)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "print(no_improvement)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
