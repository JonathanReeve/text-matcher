{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Import libraries"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "from text_matcher.matcher import Text, Matcher\n",
            "import json\n",
            "import pandas as pd\n",
            "import random\n",
            "from IPython.display import clear_output\n",
            "%matplotlib inline\n",
            "import matplotlib.pyplot as plt\n",
            "plt.rcParams[\"figure.figsize\"] = [16, 6]\n",
            "#pd.set_option('display.max_colwidth', None)\n",
            "import os, json, uuid"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Load in our Data Files\n",
            "\n",
            "üõë Input a link to the json file of articles to run the spell-check on\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Load in the JSON file with our JSTOR articles and data from TextMatcher\n",
            "# (Note: must have the file 'default.json' in the same directory as this notebook)\n",
            "articles = pd.read_json('../algorithm-testing/jstor-gender-trouble-all-articles.jsonl', lines=True)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Importing the spell-check package\n",
            "\n",
            "Languages tested:\n",
            "* English - ‚Äòen‚Äô\n",
            "* Spanish - ‚Äòes‚Äô\n",
            "* French - ‚Äòfr‚Äô\n",
            "* German - ‚Äòde‚Äô\n",
            "\n",
            "Make sure to run `pip install pyspellchecker` in terminal before running the cell below\n",
            "\n",
            "Recommended upper bound of anomaly beyond 75% percentile based on normal distribution:\n",
            "\n",
            "    mean = 0.12764241550612537\n",
            "    n = 30\n",
            "    std = 0.02330421008\n",
            "    [25 percentile, 75 percentile]: [0.1119237258,0.1433611052]\n",
            "\n",
            "    Reccomended bound: 85.66\n",
            "\n",
            "20 articles in 12.7 seconds: 0.64\n",
            "\n",
            "50 articles in 39.7 seconds: 0.79\n",
            "\n",
            "100 articles in 59.4 seconds: 0.594\n",
            "\n",
            "500 articles in 385.5 seconds: 0.77\n",
            "\n",
            "~ 0.775 seconds/article from median of 100 articles"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "from spellchecker import SpellChecker\n",
            "\n",
            "# ‚ÄºÔ∏è üõë Make sure to change the variable below to the desired accuracy bound üõë  ‚ÄºÔ∏è\n",
            "bound = 85.66\n",
            "\n",
            "#initialize dictionary pairing readability scores and article id's\n",
            "articles_read_scores = {}\n",
            "\n",
            "# goes through each row (article) in the dataframe:\n",
            "for index in range(0, 30):\n",
            "    article_index = index\n",
            "    \n",
            "    # defining variables\n",
            "    article_id  = articles['id'].loc[article_index] \n",
            "    article_text = articles['fullText'].loc[article_index]\n",
            "    article_title = articles['title'].loc[article_index]\n",
            "\n",
            "    # get articleID number\n",
            "    article_number = article_id.split('/')[-1]\n",
            "\n",
            "    # Assign the full text of this article to a variable called `cleaned_article_text`, with text-matcher's Text function\n",
            "    cleaned_article_text = Text(article_text, article_title)\n",
            "\n",
            "    word_list = cleaned_article_text.getTokens()\n",
            "    \n",
            "    # finding the document language\n",
            "    languages = ['en','fr','es','de']\n",
            "    abbrev_word_list = random.sample(word_list, int(len(word_list)/float(40)))\n",
            "    incorrect = []\n",
            "    for lg in languages:\n",
            "        spell = SpellChecker(language = lg)\n",
            "        misspelled = spell.unknown(abbrev_word_list)\n",
            "        incorrect.append(len(misspelled))\n",
            "    lang = languages[incorrect.index(min(incorrect))]\n",
            "\n",
            "    # find those words that may be misspelled\n",
            "    spell = SpellChecker(language = lang)\n",
            "    misspelled = spell.unknown(word_list)\n",
            "\n",
            "    # output the readability score \n",
            "    incorrect_percentage = float(len(misspelled))/len(word_list)\n",
            "\n",
            "    #adds the article id:[index, title, and percentage] to the dictionary\n",
            "    if (1 - incorrect_percentage) < float(bound)/100 and lang == 'en':\n",
            "        articles_read_scores[article_number] = [article_id, article_index, article_title, incorrect_percentage, lang]\n",
            "\n",
            "#articles and scores stored in dictionary articles_read_scores\n",
            "articles_scores = pd.DataFrame.from_dict(articles_read_scores, orient='index', columns=['ArticleID', 'OriginalIndex', 'Title', 'Score', 'Language'])"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Visualizing the article scores as a table"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>ArticleID</th>\n",
                     "      <th>OriginalIndex</th>\n",
                     "      <th>Title</th>\n",
                     "      <th>Score</th>\n",
                     "      <th>Language</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>40978757</th>\n",
                     "      <td>http://www.jstor.org/stable/40978757</td>\n",
                     "      <td>2</td>\n",
                     "      <td>R√©f√©rences bibliographiques des ouvrages et ar...</td>\n",
                     "      <td>0.277379</td>\n",
                     "      <td>en</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                                     ArticleID  OriginalIndex  \\\n",
                     "40978757  http://www.jstor.org/stable/40978757              2   \n",
                     "\n",
                     "                                                      Title     Score Language  \n",
                     "40978757  R√©f√©rences bibliographiques des ouvrages et ar...  0.277379       en  "
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "display(articles_scores)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Run OCR On PDF\n",
            "\n",
            "## Preparing for rerunning OCR\n",
            "\n",
            "Download the pdf's of the articles listed above and place them into a folder called 'incorrect_articles_pdfs'\n",
            "\n",
            "Name the pdfs with the corresponding articleID number (ie 409787) (JSTOR should automatically do this when you download the files)."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Rerunning OCR and Spellcheck\n",
            "\n",
            "This cell iterates through all the pdfs in the \"incorrect_articles_pdfs\" folder, reruns ocr on them, runs spellcheck on the new ocr-ed text, and replaces the article text in the json data file. \n",
            "   \n",
            "Before this can work, you need to install tesseract and all tesseract languages. This can be done with \"brew install tesseract\" and \"brew install tesseract-lang\" on Mac. For other installation, check the documenation: https://tesseract-ocr.github.io/\n",
            "\n",
            "You also need to install pdf2image, which converts the pdf into an image usuable for the tesseract OCR. Installation guide here: https://pypi.org/project/pdf2image/"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# ‚ÄºÔ∏è üõë Make sure to change the variable below to the desired replacement bound (ie how much improvement to replace the old OCR with new OCR) üõë  ‚ÄºÔ∏è\n",
            "\n",
            "replace = 0.10\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "New incorrect percentage: 0.1407035175879397\n"
               ]
            }
         ],
         "source": [
            "import pytesseract\n",
            "from pdf2image import convert_from_path\n",
            "import os\n",
            "\n",
            "# mapping of language shortcut for spellcheck to tessarect\n",
            "lang_mapping = {\n",
            "    \"en\": \"eng\",\n",
            "    \"es\": \"spa\",\n",
            "    \"fr\": \"fra\",\n",
            "    \"de\": \"deu\"\n",
            "}\n",
            "\n",
            "folder = \"incorrect_articles_pdfs\"\n",
            "\n",
            "articles_chg = pd.read_json('../algorithm-testing/jstor-gender-trouble-all-articles.jsonl', lines=True)\n",
            "\n",
            "no_improvement = {}\n",
            "\n",
            "for pdf in os.listdir(folder):\n",
            "\n",
            "    # remove the \".pdf\" to have the article_number\n",
            "    article_number = pdf[:-4]\n",
            "\n",
            "    # converts the pdf into images that are used for OCR \n",
            "    pdf_page_images = convert_from_path(\"incorrect_articles_pdfs/\" + pdf)  \n",
            "\n",
            "    pdf_lang = articles_read_scores[article_number][4]\n",
            "    article_title = articles_read_scores[article_number][2]\n",
            "\n",
            "    # run ocr \n",
            "    new_ocr_text = \"\"\n",
            "    for image in pdf_page_images[1:]:\n",
            "        new_ocr_text += pytesseract.image_to_string(image, lang=lang_mapping[pdf_lang])\n",
            "\n",
            "    # rerun spellcheck for readability score\n",
            "    spell = SpellChecker(language = pdf_lang)\n",
            "    text = Text(new_ocr_text, article_title)\n",
            "    word_list = text.getTokens()\n",
            "    misspelled = spell.unknown(word_list)\n",
            "    incorrect_percentage = float(len(misspelled))/len(word_list)\n",
            "    print(f\"New incorrect percentage for:{article_number}\", incorrect_percentage)\n",
            "\n",
            "\n",
            "    # TODO: replace texts with in json file (decide when we shold do this and whether user input should be involved)\n",
            "    old_error = articles_scores.loc[article_number, ['Score']]\n",
            "    if old_error - incorrect_percentage > 0.10:\n",
            "        articles_chg.loc[articles_scores.loc[article_number, ['OriginalIndex']],['fullText']] = new_ocr_text\n",
            "        print('+')\n",
            "    else:\n",
            "        no_improvement[article_number] = [article_number, article_title, articles_scores.loc[article_number, ['ArticleID']], old_error, pdf_lang]\n",
            "        print('-')\n",
            "\n",
            "    articles_chg.head(5)\n",
            "    "
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Replace fixable articles with new article text"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# create randomly named temporary file to avoid \n",
            "# interference with other thread/asynchronous request\n",
            "filename = '../algorithm-testing/jstor-gender-trouble-all-articles.jsonl'\n",
            "\n",
            "tempfile = os.path.join(os.path.dirname(filename), str(uuid.uuid4()))\n",
            "\n",
            "with open(tempfile, 'w') as f:\n",
            "    json.dump(articles_chg, f, indent=4)\n",
            "\n",
            "# rename temporary file replacing old file\n",
            "os.rename(tempfile, filename)"
         ]
      },
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Displays the articles that were unable to be fixed through rerunning OCR"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "no_improvement_pd = pd.DataFrame.from_dict(articles_chg, orient='index', columns=['ArticleNumber', 'ArticleTitle', 'ArticleID', 'Score', 'Language'])\n",
            "\n",
            "display(no_improvement_pd)"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
